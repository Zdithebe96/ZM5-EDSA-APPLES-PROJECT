{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import BayesianRidge, HuberRegressor, Ridge, OrthogonalMatchingPursuit\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Container</th>\n",
       "      <th>Size_Grade</th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>Date</th>\n",
       "      <th>Low_Price</th>\n",
       "      <th>High_Price</th>\n",
       "      <th>Sales_Total</th>\n",
       "      <th>Total_Qty_Sold</th>\n",
       "      <th>Total_Kg_Sold</th>\n",
       "      <th>Stock_On_Hand</th>\n",
       "      <th>avg_price_per_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAPE</td>\n",
       "      <td>M4183</td>\n",
       "      <td>1L</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>150.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>51710.0</td>\n",
       "      <td>332</td>\n",
       "      <td>6075.6</td>\n",
       "      <td>822</td>\n",
       "      <td>8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAPE</td>\n",
       "      <td>JG110</td>\n",
       "      <td>2M</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>320</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>W.CAPE-BERGRIVER ETC</td>\n",
       "      <td>JE090</td>\n",
       "      <td>2S</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>18</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1506</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CAPE</td>\n",
       "      <td>M4183</td>\n",
       "      <td>1S</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>80.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>32020.0</td>\n",
       "      <td>388</td>\n",
       "      <td>7100.4</td>\n",
       "      <td>443</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>EASTERN CAPE</td>\n",
       "      <td>IA400</td>\n",
       "      <td>1S</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Province Container Size_Grade  Weight_Kg        Date  \\\n",
       "1                   CAPE     M4183         1L       18.3  2020-09-09   \n",
       "7                   CAPE     JG110         2M       11.0  2020-04-14   \n",
       "24  W.CAPE-BERGRIVER ETC     JE090         2S        9.0  2020-04-16   \n",
       "40                  CAPE     M4183         1S       18.3  2020-05-04   \n",
       "69          EASTERN CAPE     IA400         1S      400.0  2020-09-28   \n",
       "\n",
       "    Low_Price  High_Price  Sales_Total  Total_Qty_Sold  Total_Kg_Sold  \\\n",
       "1       150.0       170.0      51710.0             332         6075.6   \n",
       "7        50.0        50.0      16000.0             320         3520.0   \n",
       "24       55.0        55.0        990.0              18          162.0   \n",
       "40       80.0       120.0      32020.0             388         7100.4   \n",
       "69     1800.0      1800.0       1800.0               1          400.0   \n",
       "\n",
       "    Stock_On_Hand  avg_price_per_kg  \n",
       "1             822              8.51  \n",
       "7               0              4.55  \n",
       "24           1506              6.11  \n",
       "40            443              4.51  \n",
       "69              2              4.50  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "\n",
    "train = pd.read_csv('df - train_set.csv')\n",
    "test = pd.read_csv('df - test_set.csv')\n",
    "\n",
    "train = train[(train['Commodities'] == 'APPLE GOLDEN DELICIOUS')]\n",
    "del train['Commodities'] \n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Province</th>\n",
       "      <th>Container</th>\n",
       "      <th>Size_Grade</th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>Date</th>\n",
       "      <th>Low_Price</th>\n",
       "      <th>High_Price</th>\n",
       "      <th>Sales_Total</th>\n",
       "      <th>Total_Qty_Sold</th>\n",
       "      <th>Total_Kg_Sold</th>\n",
       "      <th>Stock_On_Hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>W.CAPE-BERGRIVER ETC</td>\n",
       "      <td>EC120</td>\n",
       "      <td>1M</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>128.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5008.0</td>\n",
       "      <td>38</td>\n",
       "      <td>456.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>W.CAPE-BERGRIVER ETC</td>\n",
       "      <td>M4183</td>\n",
       "      <td>1X</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>8</td>\n",
       "      <td>146.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>W.CAPE-BERGRIVER ETC</td>\n",
       "      <td>EC120</td>\n",
       "      <td>1S</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>6</td>\n",
       "      <td>72.0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>W.CAPE-BERGRIVER ETC</td>\n",
       "      <td>M4183</td>\n",
       "      <td>1M</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>W.CAPE-BERGRIVER ETC</td>\n",
       "      <td>M4183</td>\n",
       "      <td>1L</td>\n",
       "      <td>18.3</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>140.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>14140.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index              Province Container Size_Grade  Weight_Kg        Date  \\\n",
       "0      1  W.CAPE-BERGRIVER ETC     EC120         1M       12.0  2020-07-09   \n",
       "1      2  W.CAPE-BERGRIVER ETC     M4183         1X       18.3  2020-01-20   \n",
       "2      3  W.CAPE-BERGRIVER ETC     EC120         1S       12.0  2020-08-19   \n",
       "3      4  W.CAPE-BERGRIVER ETC     M4183         1M       18.3  2020-05-06   \n",
       "4      5  W.CAPE-BERGRIVER ETC     M4183         1L       18.3  2020-05-04   \n",
       "\n",
       "   Low_Price  High_Price  Sales_Total  Total_Qty_Sold  Total_Kg_Sold  \\\n",
       "0      128.0       136.0       5008.0              38          456.0   \n",
       "1      220.0       220.0       1760.0               8          146.4   \n",
       "2      120.0       120.0        720.0               6           72.0   \n",
       "3      160.0       160.0        160.0               1           18.3   \n",
       "4      140.0       160.0      14140.0             100         1830.0   \n",
       "\n",
       "   Stock_On_Hand  \n",
       "0              0  \n",
       "1              2  \n",
       "2             45  \n",
       "3              8  \n",
       "4             19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test['Commodities']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1952, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 685 entries, 0 to 684\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Index           685 non-null    int64  \n",
      " 1   Province        685 non-null    object \n",
      " 2   Container       685 non-null    object \n",
      " 3   Size_Grade      685 non-null    object \n",
      " 4   Weight_Kg       685 non-null    float64\n",
      " 5   Commodities     685 non-null    object \n",
      " 6   Date            685 non-null    object \n",
      " 7   Low_Price       685 non-null    float64\n",
      " 8   High_Price      685 non-null    float64\n",
      " 9   Sales_Total     685 non-null    float64\n",
      " 10  Total_Qty_Sold  685 non-null    int64  \n",
      " 11  Total_Kg_Sold   685 non-null    float64\n",
      " 12  Stock_On_Hand   685 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(5)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>Low_Price</th>\n",
       "      <th>High_Price</th>\n",
       "      <th>Sales_Total</th>\n",
       "      <th>Total_Qty_Sold</th>\n",
       "      <th>Total_Kg_Sold</th>\n",
       "      <th>Stock_On_Hand</th>\n",
       "      <th>avg_price_per_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.460912</td>\n",
       "      <td>174.307377</td>\n",
       "      <td>215.648053</td>\n",
       "      <td>20053.533811</td>\n",
       "      <td>174.510758</td>\n",
       "      <td>2960.176332</td>\n",
       "      <td>408.393955</td>\n",
       "      <td>6.778893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>99.655169</td>\n",
       "      <td>373.553578</td>\n",
       "      <td>433.546159</td>\n",
       "      <td>39005.069445</td>\n",
       "      <td>308.810797</td>\n",
       "      <td>6097.416527</td>\n",
       "      <td>724.450582</td>\n",
       "      <td>2.248744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1325.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>219.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>5495.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>853.500000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>6.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.300000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>21082.500000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>3093.525000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>8.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "      <td>369464.000000</td>\n",
       "      <td>4237.000000</td>\n",
       "      <td>74000.000000</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>21.240000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Weight_Kg    Low_Price   High_Price    Sales_Total  Total_Qty_Sold  \\\n",
       "count  1952.000000  1952.000000  1952.000000    1952.000000     1952.000000   \n",
       "mean     40.460912   174.307377   215.648053   20053.533811      174.510758   \n",
       "std      99.655169   373.553578   433.546159   39005.069445      308.810797   \n",
       "min       3.000000     2.000000     5.000000       5.000000        1.000000   \n",
       "25%       9.000000    50.000000    60.000000    1325.000000       12.000000   \n",
       "50%      12.000000    80.000000   108.000000    5495.000000       64.000000   \n",
       "75%      18.300000   127.250000   160.000000   21082.500000      200.000000   \n",
       "max     400.000000  2300.000000  3300.000000  369464.000000     4237.000000   \n",
       "\n",
       "       Total_Kg_Sold  Stock_On_Hand  avg_price_per_kg  \n",
       "count    1952.000000    1952.000000       1952.000000  \n",
       "mean     2960.176332     408.393955          6.778893  \n",
       "std      6097.416527     724.450582          2.248744  \n",
       "min         3.000000       0.000000          0.250000  \n",
       "25%       219.600000       9.000000          5.460000  \n",
       "50%       853.500000     126.500000          6.670000  \n",
       "75%      3093.525000     468.000000          8.280000  \n",
       "max     74000.000000    6400.000000         21.240000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CAPE', 'W.CAPE-BERGRIVER ETC', 'EASTERN CAPE', 'NATAL',\n",
       "       'WEST COAST', 'TRANSVAAL', 'ORANGE FREE STATE'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M4183', 'JG110', 'JE090', 'IA400', 'EC120', 'AC030', 'M6125',\n",
       "       'EF120', 'DT063', 'M9125', 'EG140'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Container'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1L', '2M', '2S', '1S', '1M', '1X', '2L', '2U', '2X', '1U'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Size_Grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMMY\n",
    "\n",
    "def onehot_encode(df, column):\n",
    "    df = df.copy()\n",
    "    dummies = pd.get_dummies(df[column], prefix=column, drop_first=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(column, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING \n",
    "seed = 1\n",
    "def preprocess_inputs(df, return_df=False):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # CLEAN PROVINCE COLUMN\n",
    "    \n",
    "    df['Province'] = df['Province'].str.replace(' ', '_')\n",
    "    df['Province'] = df['Province'].str.replace('.', '_')\n",
    "    df['Province'] = df['Province'].str.replace('-', '_')\n",
    "    \n",
    "    # DATE ENCODING\n",
    "    # Split 'Date' column into year, month and day columns \n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Date'] = df['Date'].dt.strftime('%d.%m.%Y')\n",
    "    df['year'] = pd.DatetimeIndex(df['Date']).year\n",
    "    df['month'] = pd.DatetimeIndex(df['Date']).month\n",
    "    df['day'] = pd.DatetimeIndex(df['Date']).day\n",
    "\n",
    "    df = df.drop(['Date'], axis = 1) \n",
    "    \n",
    "    # BINARY ENCODING\n",
    "    \n",
    "    df['year'] = df['year'].replace({2020: 1, 2019: 0})\n",
    "        \n",
    "    # ONE-HOT ENCODING\n",
    "    for column in ['Province', 'Container']:\n",
    "        df = onehot_encode(df, column)\n",
    "        \n",
    "    # ORDINAL ENCODING\n",
    "    enc = OrdinalEncoder()\n",
    "    df[['Size_Grade']] = enc.fit_transform(df[['Size_Grade']])\n",
    "        \n",
    "    if return_df==True:\n",
    "        ## for training dataset\n",
    "        # REORDER COLUMNS SO THAT OUR DEPENDENT VARIABLE IS THE LAST COLUMN OF THE DATAFRAME\n",
    "        if 'avg_price_per_kg' in df.columns:\n",
    "            column_titles = [col for col in df.columns if col!= 'avg_price_per_kg'] + ['avg_price_per_kg']\n",
    "            df = df.reindex(columns = column_titles)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "        ## for training dataset\n",
    "        # REORDER COLUMNS SO THAT OUR DEPENDENT VARIABLE IS THE LAST COLUMN OF THE DATAFRAME\n",
    "    elif 'avg_price_per_kg' in df.columns:\n",
    "        column_titles = [col for col in df.columns if col!= 'avg_price_per_kg'] + ['avg_price_per_kg']\n",
    "        df = df.reindex(columns = column_titles)\n",
    "    \n",
    "        # SPLIT DATA INTO PREDICTORS AND TARGET\n",
    "    \n",
    "        y = df['avg_price_per_kg']\n",
    "        X = df.drop('avg_price_per_kg', axis=1)\n",
    "        y = np.array(y)\n",
    "        \n",
    "\n",
    "        # SCALE\n",
    "        #x_scaler = StandardScaler()\n",
    "        #y_scaler = StandardScaler()\n",
    "\n",
    "        #X_scaled = x_scaler.fit_transform(X) \n",
    "        #y_scaled = y_scaler.fit_transform(y.reshape(-1, 1)) \n",
    "        \n",
    "        # TRAIN TEST SPLIT\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, shuffle=False, random_state=seed)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "        \n",
    "    else:\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_inputs(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression trained.\n",
      " Linear Regression (L2 Regularization) trained.\n",
      " Linear Regression (L1 Regularization) trained.\n",
      "                   K-Nearest Neighbors trained.\n",
      "                        Neural Network trained.\n",
      "Support Vector Machine (Linear Kernel) trained.\n",
      "   Support Vector Machine (RBF Kernel) trained.\n",
      "                         Decision Tree trained.\n",
      "                         Random Forest trained.\n",
      "                     Gradient Boosting trained.\n",
      "                               XGBoost trained.\n",
      "                         BayesianRidge trained.\n",
      "                        HuberRegressor trained.\n",
      "                     CatBoostRegressor trained.\n",
      "             OrthogonalMatchingPursuit trained.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN A FEW MODELS\n",
    "\n",
    "models = {\n",
    "    \"                     Linear Regression\": LinearRegression(),\n",
    "    \" Linear Regression (L2 Regularization)\": Ridge(),\n",
    "    \" Linear Regression (L1 Regularization)\": Lasso(),\n",
    "    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"                        Neural Network\": MLPRegressor(),\n",
    "    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n",
    "    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n",
    "    \"                         Decision Tree\": DecisionTreeRegressor(random_state= seed),\n",
    "    \"                         Random Forest\": RandomForestRegressor(n_estimators=442, random_state= seed),\n",
    "    \"                     Gradient Boosting\": GradientBoostingRegressor(n_estimators=442, random_state= seed),\n",
    "    \"                               XGBoost\": XGBRegressor(max_depth=3,min_child_weight=3,subsample=1,colsample_bytree=1,\n",
    "            objective='reg:squarederror',n_estimators=442, learning_rate=0.1, random_state= seed),\n",
    "    \"                         BayesianRidge\": BayesianRidge(),\n",
    "    \"                        HuberRegressor\": HuberRegressor(),\n",
    "    \"                     CatBoostRegressor\": CatBoostRegressor(verbose=0),\n",
    "    \"             OrthogonalMatchingPursuit\": OrthogonalMatchingPursuit()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression R^2 Score: 0.46372\n",
      " Linear Regression (L2 Regularization) R^2 Score: 0.46209\n",
      " Linear Regression (L1 Regularization) R^2 Score: 0.27848\n",
      "                   K-Nearest Neighbors R^2 Score: 0.80900\n",
      "                        Neural Network R^2 Score: -6.21105\n",
      "Support Vector Machine (Linear Kernel) R^2 Score: -292.74801\n",
      "   Support Vector Machine (RBF Kernel) R^2 Score: 0.28180\n",
      "                         Decision Tree R^2 Score: 0.89764\n",
      "                         Random Forest R^2 Score: 0.97741\n",
      "                     Gradient Boosting R^2 Score: 0.97603\n",
      "                               XGBoost R^2 Score: 0.97932\n",
      "                         BayesianRidge R^2 Score: 0.46174\n",
      "                        HuberRegressor R^2 Score: -2.11969\n",
      "                     CatBoostRegressor R^2 Score: 0.97932\n",
      "             OrthogonalMatchingPursuit R^2 Score: 0.39464\n"
     ]
    }
   ],
   "source": [
    "#EVALUATE MODEL ON R SQUARED - HIGHER IS BETTER\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(name + \" R^2 Score: {:.5f}\".format(model.score(X_test, y_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression Test RMSE: 1.53024\n",
      "                     Linear Regression Train RMSE: 1.41372\n",
      "Mean Absolute Error: 1.15 Rand.\n",
      "Accuracy: 74.31 %.\n",
      " Linear Regression (L2 Regularization) Test RMSE: 1.53257\n",
      " Linear Regression (L2 Regularization) Train RMSE: 1.41424\n",
      "Mean Absolute Error: 1.15 Rand.\n",
      "Accuracy: 74.07 %.\n",
      " Linear Regression (L1 Regularization) Test RMSE: 1.77496\n",
      " Linear Regression (L1 Regularization) Train RMSE: 1.70080\n",
      "Mean Absolute Error: 1.24 Rand.\n",
      "Accuracy: 69.92 %.\n",
      "                   K-Nearest Neighbors Test RMSE: 0.91322\n",
      "                   K-Nearest Neighbors Train RMSE: 0.77752\n",
      "Mean Absolute Error: 0.66 Rand.\n",
      "Accuracy: 86.95 %.\n",
      "                        Neural Network Test RMSE: 5.61129\n",
      "                        Neural Network Train RMSE: 5.22232\n",
      "Mean Absolute Error: 3.99 Rand.\n",
      "Accuracy: 25.52 %.\n",
      "Support Vector Machine (Linear Kernel) Test RMSE: 35.81388\n",
      "Support Vector Machine (Linear Kernel) Train RMSE: 27.00464\n",
      "Mean Absolute Error: 12.13 Rand.\n",
      "Accuracy: -121.04 %.\n",
      "   Support Vector Machine (RBF Kernel) Test RMSE: 1.77087\n",
      "   Support Vector Machine (RBF Kernel) Train RMSE: 1.99894\n",
      "Mean Absolute Error: 1.39 Rand.\n",
      "Accuracy: 68.35 %.\n",
      "                         Decision Tree Test RMSE: 0.66856\n",
      "                         Decision Tree Train RMSE: 0.00000\n",
      "Mean Absolute Error: 0.37 Rand.\n",
      "Accuracy: 92.53 %.\n",
      "                         Random Forest Test RMSE: 0.31410\n",
      "                         Random Forest Train RMSE: 0.22652\n",
      "Mean Absolute Error: 0.22 Rand.\n",
      "Accuracy: 95.5 %.\n",
      "                     Gradient Boosting Test RMSE: 0.32352\n",
      "                     Gradient Boosting Train RMSE: 0.21437\n",
      "Mean Absolute Error: 0.23 Rand.\n",
      "Accuracy: 95.82 %.\n",
      "                               XGBoost Test RMSE: 0.30049\n",
      "                               XGBoost Train RMSE: 0.24729\n",
      "Mean Absolute Error: 0.22 Rand.\n",
      "Accuracy: 95.74 %.\n",
      "                         BayesianRidge Test RMSE: 1.53306\n",
      "                         BayesianRidge Train RMSE: 1.41574\n",
      "Mean Absolute Error: 1.15 Rand.\n",
      "Accuracy: 73.88 %.\n",
      "                        HuberRegressor Test RMSE: 3.69079\n",
      "                        HuberRegressor Train RMSE: 4.74476\n",
      "Mean Absolute Error: 2.67 Rand.\n",
      "Accuracy: 46.58 %.\n",
      "                     CatBoostRegressor Test RMSE: 0.30050\n",
      "                     CatBoostRegressor Train RMSE: 0.20711\n",
      "Mean Absolute Error: 0.23 Rand.\n",
      "Accuracy: 95.6 %.\n",
      "             OrthogonalMatchingPursuit Test RMSE: 1.62581\n",
      "             OrthogonalMatchingPursuit Train RMSE: 1.82723\n",
      "Mean Absolute Error: 1.22 Rand.\n",
      "Accuracy: 71.68 %.\n"
     ]
    }
   ],
   "source": [
    "#EVALUATE MODEL ON RMSE - LOWER IS BETTER\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name + \" Test RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_test ,y_pred))))\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(name + \" Train RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_train_pred ,y_train))))\n",
    "    \n",
    "    errors = abs(y_pred - y_test)\n",
    "\n",
    "    # Display the performance metrics\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2), 'Rand.')\n",
    "\n",
    "    mape = np.mean(100 * (errors / y_test))\n",
    "    accuracy = 100 - mape\n",
    "\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE CSV FOR SUBMISSION TO KAGGLE\n",
    "# DON'T SUBMIT ALL, ONLY THOSE WHICH DID GOOD ON EVALUATION TO CONFIRM\n",
    "\n",
    "df = preprocess_inputs(test)\n",
    "\n",
    "Xs = list(df.columns)\n",
    "Xs.remove('Index')\n",
    "\n",
    "X_test = df[Xs]\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    d = pd.DataFrame(y_pred, columns =['avg_price_per_kg'])\n",
    "    dff = pd.concat([df['Index'], d], axis=1)\n",
    "    dff = dff.set_index('Index')\n",
    "    \n",
    "    match= re.findall('[A-Z]', name)    \n",
    "    matchno = re.findall('[0-9]+', name)   \n",
    "    file_name = ''.join(match) + ''.join(matchno)\n",
    "    if file_name == 'XGB':\n",
    "        dff.to_csv(file_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Weight_Kg            Importance: 0.3799999952316284\n",
      "Variable: Low_Price            Importance: 0.17000000178813934\n",
      "Variable: High_Price           Importance: 0.15000000596046448\n",
      "Variable: Province_NATAL       Importance: 0.11999999731779099\n",
      "Variable: year                 Importance: 0.029999999329447746\n",
      "Variable: Sales_Total          Importance: 0.019999999552965164\n",
      "Variable: Container_JE090      Importance: 0.019999999552965164\n",
      "Variable: Container_JG110      Importance: 0.019999999552965164\n",
      "Variable: Size_Grade           Importance: 0.009999999776482582\n",
      "Variable: Total_Kg_Sold        Importance: 0.009999999776482582\n",
      "Variable: Stock_On_Hand        Importance: 0.009999999776482582\n",
      "Variable: month                Importance: 0.009999999776482582\n",
      "Variable: Province_EASTERN_CAPE Importance: 0.009999999776482582\n",
      "Variable: Province_W_CAPE_BERGRIVER_ETC Importance: 0.009999999776482582\n",
      "Variable: Container_EC120      Importance: 0.009999999776482582\n",
      "Variable: Container_M4183      Importance: 0.009999999776482582\n",
      "Variable: Total_Qty_Sold       Importance: 0.0\n",
      "Variable: day                  Importance: 0.0\n",
      "Variable: Province_ORANGE_FREE_STATE Importance: 0.0\n",
      "Variable: Province_TRANSVAAL   Importance: 0.0\n",
      "Variable: Province_WEST_COAST  Importance: 0.0\n",
      "Variable: Container_DT063      Importance: 0.0\n",
      "Variable: Container_EF120      Importance: 0.0\n",
      "Variable: Container_EG140      Importance: 0.0\n",
      "Variable: Container_IA400      Importance: 0.0\n",
      "Variable: Container_M6125      Importance: 0.0\n",
      "Variable: Container_M9125      Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# FEAUTURE IMPORTANCES\n",
    "\n",
    "df = train.drop('avg_price_per_kg', axis = 1)\n",
    "features = preprocess_inputs(df)\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == \"                               XGBoost\":\n",
    "        # Get numerical feature importances\n",
    "        importances = list(model.feature_importances_)\n",
    "\n",
    "        # List of tuples with variable and importance\n",
    "        feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "        # Sort the feature importances by most important first\n",
    "        feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "        # Print out the feature and importances \n",
    "        [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECTING IMPORTANT FEATURES\n",
    "\n",
    "df = preprocess_inputs(train, return_df=True)\n",
    "\n",
    "\n",
    "y = df['avg_price_per_kg']\n",
    "X = df.drop('avg_price_per_kg', axis=1)\n",
    "\n",
    "# GET IMPORTANT COLUMN NAMES\n",
    "\n",
    "important = []\n",
    "for i in ['Low_Price', 'Total_Kg_Sold', 'Container_IA400', 'Weight_Kg', 'Total_Qty_Sold', 'High_Price', 'Sales_Total']:\n",
    "    A = [col for col in df.columns if i in col]\n",
    "    important.append(A)\n",
    "    \n",
    "important_list = [item for sublist in important for item in sublist]\n",
    "\n",
    "# IMPORTANT DATAFRAME\n",
    "X_imp = X[important_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained.\n"
     ]
    }
   ],
   "source": [
    "# TEST NEW MODEL WITH IMPORTANT FEATURES ONLY\n",
    "\n",
    "X_imp_train, X_imp_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.02, shuffle=False, random_state=seed)\n",
    "\n",
    "xgb = XGBRegressor(max_depth=3,min_child_weight=3,subsample=1,colsample_bytree=1,\n",
    "            objective='reg:squarederror',n_estimators=442, learning_rate=0.1, random_state= seed)\n",
    "\n",
    "xgb.fit(X_imp_train, y_train)\n",
    "\n",
    "print(\"Trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.22 degrees.\n",
      "Accuracy: 95.75 %.\n",
      "Test RMSE: 0.31163\n",
      "Train RMSE: 0.25125\n"
     ]
    }
   ],
   "source": [
    "# CHECK PERFORMANCE METRICS\n",
    "\n",
    "pred = xgb.predict(X_imp_test)\n",
    "\n",
    "errors = abs(pred - y_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "mape = np.mean(100 * (errors / y_test))\n",
    "accuracy = 100 - mape\n",
    "\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "print(\"Test RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_test ,pred))))\n",
    "y_train_pred = xgb.predict(X_imp_train)\n",
    "print(\"Train RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_train_pred ,y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare all the models with their previous score rather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression trained.\n",
      " Linear Regression (L2 Regularization) trained.\n",
      " Linear Regression (L1 Regularization) trained.\n",
      "                   K-Nearest Neighbors trained.\n",
      "                        Neural Network trained.\n",
      "Support Vector Machine (Linear Kernel) trained.\n",
      "   Support Vector Machine (RBF Kernel) trained.\n",
      "                         Decision Tree trained.\n",
      "                         Random Forest trained.\n",
      "                     Gradient Boosting trained.\n",
      "                               XGBoost trained.\n",
      "                         BayesianRidge trained.\n",
      "                        HuberRegressor trained.\n",
      "                     CatBoostRegressor trained.\n",
      "             OrthogonalMatchingPursuit trained.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODELS AGAIN BUT WITH THE SUBSET CREATER ABOVE\n",
    "\n",
    "X_imp_train, X_imp_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.02, shuffle=False, random_state=seed)\n",
    "\n",
    "models = {\n",
    "    \"                     Linear Regression\": LinearRegression(),\n",
    "    \" Linear Regression (L2 Regularization)\": Ridge(),\n",
    "    \" Linear Regression (L1 Regularization)\": Lasso(),\n",
    "    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"                        Neural Network\": MLPRegressor(),\n",
    "    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n",
    "    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n",
    "    \"                         Decision Tree\": DecisionTreeRegressor(random_state= seed),\n",
    "    \"                         Random Forest\": RandomForestRegressor(n_estimators=442, random_state= seed),\n",
    "    \"                     Gradient Boosting\": GradientBoostingRegressor(n_estimators=442, random_state= seed),\n",
    "    \"                               XGBoost\": XGBRegressor(max_depth=3,min_child_weight=3,subsample=1,colsample_bytree=1,\n",
    "            objective='reg:squarederror',n_estimators=442, learning_rate=0.1, random_state= seed),\n",
    "    \"                         BayesianRidge\": BayesianRidge(),\n",
    "    \"                        HuberRegressor\": HuberRegressor(),\n",
    "    \"                     CatBoostRegressor\": CatBoostRegressor(verbose=0),\n",
    "    \"             OrthogonalMatchingPursuit\": OrthogonalMatchingPursuit()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_imp_train, y_train)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression R^2 Score: 0.38435\n",
      " Linear Regression (L2 Regularization) R^2 Score: 0.20706\n",
      " Linear Regression (L1 Regularization) R^2 Score: 0.16335\n",
      "                   K-Nearest Neighbors R^2 Score: 0.92132\n",
      "                        Neural Network R^2 Score: -31.49171\n",
      "Support Vector Machine (Linear Kernel) R^2 Score: -1066.10783\n",
      "   Support Vector Machine (RBF Kernel) R^2 Score: 0.28546\n",
      "                         Decision Tree R^2 Score: 0.96323\n",
      "                         Random Forest R^2 Score: 0.97814\n",
      "                     Gradient Boosting R^2 Score: 0.98218\n",
      "                               XGBoost R^2 Score: 0.97776\n",
      "                         BayesianRidge R^2 Score: 0.38137\n",
      "                        HuberRegressor R^2 Score: -30.83005\n",
      "                     CatBoostRegressor R^2 Score: 0.98433\n",
      "             OrthogonalMatchingPursuit R^2 Score: 0.02380\n"
     ]
    }
   ],
   "source": [
    "#EVALUATE SQUARED - HIGHER IS BETTER\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(name + \" R^2 Score: {:.5f}\".format(model.score(X_imp_test, y_test)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression Test RMSE: 1.63958\n",
      "                     Linear Regression Train RMSE: 1.65937\n",
      "Mean Absolute Error: 1.19 degrees.\n",
      "Accuracy: 72.37 %.\n",
      " Linear Regression (L2 Regularization) Test RMSE: 1.86073\n",
      " Linear Regression (L2 Regularization) Train RMSE: 1.75260\n",
      "Mean Absolute Error: 1.3 degrees.\n",
      "Accuracy: 68.58 %.\n",
      " Linear Regression (L1 Regularization) Test RMSE: 1.91134\n",
      " Linear Regression (L1 Regularization) Train RMSE: 1.78442\n",
      "Mean Absolute Error: 1.34 degrees.\n",
      "Accuracy: 67.65 %.\n",
      "                   K-Nearest Neighbors Test RMSE: 0.58613\n",
      "                   K-Nearest Neighbors Train RMSE: 0.62157\n",
      "Mean Absolute Error: 0.41 degrees.\n",
      "Accuracy: 92.0 %.\n",
      "                        Neural Network Test RMSE: 11.91105\n",
      "                        Neural Network Train RMSE: 9.84465\n",
      "Mean Absolute Error: 6.91 degrees.\n",
      "Accuracy: -8.75 %.\n",
      "Support Vector Machine (Linear Kernel) Test RMSE: 68.26028\n",
      "Support Vector Machine (Linear Kernel) Train RMSE: 52.31970\n",
      "Mean Absolute Error: 28.93 degrees.\n",
      "Accuracy: -313.78 %.\n",
      "   Support Vector Machine (RBF Kernel) Test RMSE: 1.76636\n",
      "   Support Vector Machine (RBF Kernel) Train RMSE: 1.99546\n",
      "Mean Absolute Error: 1.38 degrees.\n",
      "Accuracy: 68.46 %.\n",
      "                         Decision Tree Test RMSE: 0.40070\n",
      "                         Decision Tree Train RMSE: 0.00000\n",
      "Mean Absolute Error: 0.24 degrees.\n",
      "Accuracy: 95.3 %.\n",
      "                         Random Forest Test RMSE: 0.30897\n",
      "                         Random Forest Train RMSE: 0.22091\n",
      "Mean Absolute Error: 0.21 degrees.\n",
      "Accuracy: 95.91 %.\n",
      "                     Gradient Boosting Test RMSE: 0.27898\n",
      "                     Gradient Boosting Train RMSE: 0.22396\n",
      "Mean Absolute Error: 0.2 degrees.\n",
      "Accuracy: 96.38 %.\n",
      "                               XGBoost Test RMSE: 0.31163\n",
      "                               XGBoost Train RMSE: 0.25125\n",
      "Mean Absolute Error: 0.22 degrees.\n",
      "Accuracy: 95.75 %.\n",
      "                         BayesianRidge Test RMSE: 1.64354\n",
      "                         BayesianRidge Train RMSE: 1.65944\n",
      "Mean Absolute Error: 1.2 degrees.\n",
      "Accuracy: 72.28 %.\n",
      "                        HuberRegressor Test RMSE: 11.78915\n",
      "                        HuberRegressor Train RMSE: 9.14861\n",
      "Mean Absolute Error: 6.72 degrees.\n",
      "Accuracy: -34.29 %.\n",
      "                     CatBoostRegressor Test RMSE: 0.26154\n",
      "                     CatBoostRegressor Train RMSE: 0.22049\n",
      "Mean Absolute Error: 0.19 degrees.\n",
      "Accuracy: 96.44 %.\n",
      "             OrthogonalMatchingPursuit Test RMSE: 2.06459\n",
      "             OrthogonalMatchingPursuit Train RMSE: 2.10206\n",
      "Mean Absolute Error: 1.58 degrees.\n",
      "Accuracy: 62.95 %.\n"
     ]
    }
   ],
   "source": [
    "#EVALUATE MODEL ON RMSE\n",
    "\n",
    "X_imp_train, X_imp_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.02, shuffle=False, random_state=seed)\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_imp_test)\n",
    "    print(name + \" Test RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_test ,y_pred))))\n",
    "    \n",
    "    y_train_pred = model.predict(X_imp_train)\n",
    "    print(name + \" Train RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error( y_train,y_train_pred))))\n",
    "    \n",
    "    errors = abs(y_pred - y_test)\n",
    "\n",
    "    # Display the performance metrics\n",
    "    print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "    mape = np.mean(100 * (errors / y_test))\n",
    "    accuracy = 100 - mape\n",
    "\n",
    "    print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It apears the majority of the best performing models from our initial training have improved. Lets improve them a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW ENSEMBLE STACKING\n",
    "\n",
    "# CHOOSE BEST MODELS FROM EARLIER SCORES\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators= 442, random_state= seed)\n",
    "gb =GradientBoostingRegressor(random_state= seed, n_estimators=442)\n",
    "xgb = XGBRegressor(max_depth=3,min_child_weight=3,subsample=1,colsample_bytree=1,\n",
    "            objective='reg:squarederror',n_estimators=442, learning_rate=0.1, random_state= seed)\n",
    "cb= CatBoostRegressor(verbose=0, learning_rate=0.1)\n",
    "dt = DecisionTreeRegressor(random_state= seed)\n",
    "\n",
    "meta_learner_reg = CatBoostRegressor(verbose=0, learning_rate=0.1)\n",
    "\n",
    "\n",
    "model_4st = [(\"rf\", rf),(\"gb\", gb),(\"xgb\", xgb), ('cb', cb), ('dt', dt)]\n",
    "\n",
    "s_reg = StackingRegressor(estimators=model_4st, final_estimator= meta_learner_reg, passthrough = True, cv= 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked model fitted.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ON DATAFRAME WITH 7 COLUMNS(MOST IMPORTANT)\n",
    "\n",
    "X_imp_train, X_imp_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.02, shuffle=False, random_state=seed)\n",
    "\n",
    "s_reg.fit(X_imp_train,y_train)\n",
    "print(\"Stacked model fitted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp_train, X_imp_test, y_train, y_test = train_test_split(X_imp, y, test_size=0.02, shuffle=False, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score:  0.980916920053333\n",
      "Test RMSE: 0.28866\n",
      "Train RMSE: 0.23686\n",
      "Mean Absolute Error: 0.2 degrees.\n",
      "Accuracy: 96.32 %.\n"
     ]
    }
   ],
   "source": [
    "# METRICS OF STACKING REGRESSOR\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_inputs(train)\n",
    "\n",
    "y_pred = s_reg.predict(X_imp_test)\n",
    "rsq = s_reg.score(X_imp_test, y_test)\n",
    "print(\"R^2 Score: \", rsq)\n",
    "\n",
    "print(\"Test RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error( y_test,y_pred))))\n",
    "y_train_pred = s_reg.predict(X_imp_train)\n",
    "print(\"Train RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_train_pred ,y_train))))\n",
    " \n",
    "errors = abs(y_pred - y_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = np.mean(100 * (errors / y_test))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_inputs(test)\n",
    "Xs = list(df.columns)\n",
    "Xs.remove('Index')\n",
    "\n",
    "X_test = df[Xs]\n",
    "\n",
    "x_t = X_test[important_list]\n",
    "\n",
    "y_pred = s_reg.predict(x_t)\n",
    "d = pd.DataFrame(y_pred, columns =['avg_price_per_kg'])\n",
    "dff = pd.concat([df['Index'], d], axis=1)\n",
    "dff = dff.set_index('Index')\n",
    "dff.to_csv('StackeD27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = []\n",
    "for i in ['Low_Price', 'Total_Kg_Sold', 'Container_IA400', 'Weight_Kg', 'Total_Qty_Sold', 'High_Price', 'Sales_Total']:\n",
    "    A = [col for col in df.columns if i in col]\n",
    "    important.append(A)\n",
    "    \n",
    "important_list = [item for sublist in important for item in sublist]\n",
    "\n",
    "# IMPORTANT DATAFRAME\n",
    "X_imp = X[important_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING KFOLD\n",
    "\n",
    "df = preprocess_inputs(train, return_df=True)\n",
    "\n",
    "important = []\n",
    "for i in ['Low_Price', 'Total_Kg_Sold', 'Container_IA400', 'Weight_Kg', 'Total_Qty_Sold', 'High_Price', 'Sales_Total']:\n",
    "    A = [col for col in df.columns if i in col]\n",
    "    important.append(A)\n",
    "    \n",
    "important_list = [item for sublist in important for item in sublist]\n",
    "\n",
    "\n",
    "def split_data_kf(df,K):\n",
    "    \n",
    "    y = df['avg_price_per_kg']\n",
    "    X = df[important_list]  # SUBSET FOR IMPORTANT ROWS\n",
    "    \n",
    "    kf = KFold(n_splits=K, shuffle = False)\n",
    "    indices = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        indices.append((train_index, test_index))\n",
    "        \n",
    "    return indices\n",
    "\n",
    "\n",
    "def get_best_kfmodel(df,data_indices):\n",
    "    y = df['avg_price_per_kg']\n",
    "    X = df[important_list]\n",
    "    \n",
    "    RMSE = []\n",
    "    trainRSME =[]\n",
    "    \n",
    "    for (train_indices,test_indices) in data_indices:\n",
    "        X_train, y_train = X.iloc[train_indices,:],y.iloc[train_indices]\n",
    "        X_test, y_test = X.iloc[test_indices,:], y.iloc[test_indices]\n",
    "        \n",
    "        model = StackingRegressor(estimators=model_4st, final_estimator= meta_learner_reg, passthrough = True, cv= 4)\n",
    "        \n",
    "        model.fit(X_train, y_train) \n",
    "\n",
    "        y_pred = model.predict(X_test)     \n",
    "        \n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test ,y_pred))\n",
    "        RMSE.append(rmse)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        \n",
    "        train_rsme = np.sqrt(metrics.mean_squared_error( y_train,y_train_pred))\n",
    "        trainRSME.append(train_rsme)\n",
    "        \n",
    "    best = RMSE.index(min(RMSE))\n",
    "    best_indicies = data_indices[best]\n",
    "    \n",
    "    \n",
    "    X_train, y_train = X.iloc[best_indicies[0],:],y.iloc[best_indicies[0]]\n",
    "    X_test, y_test = X.iloc[best_indicies[1],:], y.iloc[best_indicies[1]]\n",
    "    \n",
    "    model = StackingRegressor(estimators=model_4st, final_estimator= meta_learner_reg, passthrough = True, cv= 4)\n",
    "    \n",
    "    model.fit(X_train, y_train)       \n",
    "          \n",
    "    return trainRSME, RMSE\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.159509151550616,\n",
       "  0.29588091344308826,\n",
       "  0.24568148722113006,\n",
       "  0.26808761513218066],\n",
       " [0.6827825330873297,\n",
       "  0.3950390501902279,\n",
       "  0.4077639508599942,\n",
       "  0.4600179831132657])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess_inputs(train, return_df = True)\n",
    "data_indices = split_data_kf(df,4)\n",
    "\n",
    "get_best_kfmodel(df,data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important_list = [item for sublist in important for item in sublist]\n",
    "\n",
    "#train_df = preprocess_inputs(train, return_df = True)\n",
    "#data_indices = split_data_kf(train_df,4)\n",
    "#model = get_best_kfmodel(train_df,data_indices)\n",
    "\n",
    "df = preprocess_inputs(test)\n",
    "Xs = list(df.columns)\n",
    "Xs.remove('Index')\n",
    "\n",
    "X_test = df[Xs]\n",
    "X_Test_imp = X_test[important_list]\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "d = pd.DataFrame(y_pred, columns =['avg_price_per_kg'])\n",
    "dff = pd.concat([df['Index'], d], axis=1)\n",
    "dff = dff.set_index('Index')\n",
    "dff.to_csv('xgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "### XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:4.24003\n",
      "[1]\tTest-rmse:2.95083\n",
      "[2]\tTest-rmse:2.07685\n",
      "[3]\tTest-rmse:1.45692\n",
      "[4]\tTest-rmse:1.03832\n",
      "[5]\tTest-rmse:0.74636\n",
      "[6]\tTest-rmse:0.55419\n",
      "[7]\tTest-rmse:0.44213\n",
      "[8]\tTest-rmse:0.37587\n",
      "[9]\tTest-rmse:0.34743\n",
      "[10]\tTest-rmse:0.33719\n",
      "[11]\tTest-rmse:0.32814\n",
      "[12]\tTest-rmse:0.31795\n",
      "[13]\tTest-rmse:0.32059\n",
      "[14]\tTest-rmse:0.32324\n",
      "[15]\tTest-rmse:0.33245\n",
      "[16]\tTest-rmse:0.32408\n",
      "[17]\tTest-rmse:0.31866\n",
      "[18]\tTest-rmse:0.32190\n",
      "[19]\tTest-rmse:0.31826\n",
      "[20]\tTest-rmse:0.31532\n",
      "[21]\tTest-rmse:0.31433\n",
      "[22]\tTest-rmse:0.31612\n",
      "[23]\tTest-rmse:0.31563\n",
      "[24]\tTest-rmse:0.31012\n",
      "[25]\tTest-rmse:0.31401\n",
      "[26]\tTest-rmse:0.31333\n",
      "[27]\tTest-rmse:0.31418\n",
      "[28]\tTest-rmse:0.31419\n",
      "[29]\tTest-rmse:0.31111\n",
      "[30]\tTest-rmse:0.31438\n",
      "[31]\tTest-rmse:0.31141\n",
      "[32]\tTest-rmse:0.31090\n",
      "[33]\tTest-rmse:0.31058\n",
      "[34]\tTest-rmse:0.31162\n",
      "Best RMSE: 0.31 with 25 rounds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_inputs(train)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "\n",
    "params['eval_metric'] = \"rmse\"\n",
    "num_boost_round = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "print(\"Best RMSE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.759979</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>4.759272</td>\n",
       "      <td>0.042933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.434726</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>3.438186</td>\n",
       "      <td>0.044566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.527619</td>\n",
       "      <td>0.013353</td>\n",
       "      <td>2.537529</td>\n",
       "      <td>0.049325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.917172</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>1.934875</td>\n",
       "      <td>0.060541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.499747</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>1.519129</td>\n",
       "      <td>0.069289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.157172</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.531166</td>\n",
       "      <td>0.084704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.156778</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.531033</td>\n",
       "      <td>0.084783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.156232</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.530817</td>\n",
       "      <td>0.084777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.155791</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.530773</td>\n",
       "      <td>0.084872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.155173</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.530134</td>\n",
       "      <td>0.084440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0           4.759979        0.010120        4.759272       0.042933\n",
       "1           3.434726        0.012340        3.438186       0.044566\n",
       "2           2.527619        0.013353        2.537529       0.049325\n",
       "3           1.917172        0.017705        1.934875       0.060541\n",
       "4           1.499747        0.021379        1.519129       0.069289\n",
       "..               ...             ...             ...            ...\n",
       "241         0.157172        0.002792        0.531166       0.084704\n",
       "242         0.156778        0.002842        0.531033       0.084783\n",
       "243         0.156232        0.003002        0.530817       0.084777\n",
       "244         0.155791        0.003105        0.530773       0.084872\n",
       "245         0.155173        0.003146        0.530134       0.084440\n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=1,\n",
    "    nfold=4,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5301345"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=3, min_child_weight=3\n",
      "\tRMSE 0.5082641999999999 for 544 rounds\n",
      "CV with max_depth=3, min_child_weight=4\n",
      "\tRMSE 0.5196882 for 505 rounds\n",
      "CV with max_depth=3, min_child_weight=5\n",
      "\tRMSE 0.5191416 for 431 rounds\n",
      "CV with max_depth=3, min_child_weight=6\n",
      "\tRMSE 0.5340222000000001 for 253 rounds\n",
      "Best params: 3, 3, RMSE: 0.5082641999999999\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,4)\n",
    "    for min_child_weight in range(3,7)\n",
    "]\n",
    "\n",
    "# Define initial best params and RMSE\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=1,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10)\n",
    "    \n",
    "    # Update best RMSE\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    \n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "        \n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tRMSE 0.5007085 for 761 rounds\n",
      "Best params: 1.0, 1.0, RMSE: 0.5007085\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [10/10. for i in range(10,11)]\n",
    "    for colsample in [10/10. for i in range(10,11)]\n",
    "]\n",
    "\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(subsample, colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=1,\n",
    "        nfold=4,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10)\n",
    "    \n",
    "    # Update best score\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 3.62 s\n",
      "\tRMSE 0.5007085 for 761 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "Wall time: 2.84 s\n",
      "\tRMSE 0.5086425 for 618 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "Wall time: 4.56 s\n",
      "\tRMSE 0.51088125 for 996 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "Wall time: 4.7 s\n",
      "\tRMSE 0.5370935 for 998 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "Wall time: 4.57 s\n",
      "\tRMSE 0.63481625 for 998 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "Wall time: 4.64 s\n",
      "\tRMSE 0.72191725 for 998 rounds\n",
      "\n",
      "Best params: 0.3, RMSE: 0.5007085\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    \n",
    "    %time cv_results = xgb.cv(params, dtrain,num_boost_round=num_boost_round,seed=1, nfold=4, metrics=['rmse'], early_stopping_rounds=10)\n",
    "    \n",
    "    # Update best score\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\\n\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'min_child_weight': 6,\n",
       " 'eta': 0.1,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'eval_metric': 'rmse'}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['eta'] = .1\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:5.48784\n",
      "[1]\tTest-rmse:4.93565\n",
      "[2]\tTest-rmse:4.43379\n",
      "[3]\tTest-rmse:3.98805\n",
      "[4]\tTest-rmse:3.59204\n",
      "[5]\tTest-rmse:3.22469\n",
      "[6]\tTest-rmse:2.91537\n",
      "[7]\tTest-rmse:2.63697\n",
      "[8]\tTest-rmse:2.38234\n",
      "[9]\tTest-rmse:2.15274\n",
      "[10]\tTest-rmse:1.95026\n",
      "[11]\tTest-rmse:1.76234\n",
      "[12]\tTest-rmse:1.58760\n",
      "[13]\tTest-rmse:1.45094\n",
      "[14]\tTest-rmse:1.32922\n",
      "[15]\tTest-rmse:1.20769\n",
      "[16]\tTest-rmse:1.11868\n",
      "[17]\tTest-rmse:1.02924\n",
      "[18]\tTest-rmse:0.95382\n",
      "[19]\tTest-rmse:0.88946\n",
      "[20]\tTest-rmse:0.83332\n",
      "[21]\tTest-rmse:0.78195\n",
      "[22]\tTest-rmse:0.74035\n",
      "[23]\tTest-rmse:0.70253\n",
      "[24]\tTest-rmse:0.66709\n",
      "[25]\tTest-rmse:0.63953\n",
      "[26]\tTest-rmse:0.61081\n",
      "[27]\tTest-rmse:0.59781\n",
      "[28]\tTest-rmse:0.58291\n",
      "[29]\tTest-rmse:0.56744\n",
      "[30]\tTest-rmse:0.55616\n",
      "[31]\tTest-rmse:0.54495\n",
      "[32]\tTest-rmse:0.53250\n",
      "[33]\tTest-rmse:0.52379\n",
      "[34]\tTest-rmse:0.51979\n",
      "[35]\tTest-rmse:0.50646\n",
      "[36]\tTest-rmse:0.49441\n",
      "[37]\tTest-rmse:0.48813\n",
      "[38]\tTest-rmse:0.48440\n",
      "[39]\tTest-rmse:0.47901\n",
      "[40]\tTest-rmse:0.47588\n",
      "[41]\tTest-rmse:0.46967\n",
      "[42]\tTest-rmse:0.46096\n",
      "[43]\tTest-rmse:0.46103\n",
      "[44]\tTest-rmse:0.46069\n",
      "[45]\tTest-rmse:0.45675\n",
      "[46]\tTest-rmse:0.45822\n",
      "[47]\tTest-rmse:0.45154\n",
      "[48]\tTest-rmse:0.45007\n",
      "[49]\tTest-rmse:0.45200\n",
      "[50]\tTest-rmse:0.44363\n",
      "[51]\tTest-rmse:0.43684\n",
      "[52]\tTest-rmse:0.43689\n",
      "[53]\tTest-rmse:0.43306\n",
      "[54]\tTest-rmse:0.43128\n",
      "[55]\tTest-rmse:0.42956\n",
      "[56]\tTest-rmse:0.42866\n",
      "[57]\tTest-rmse:0.42416\n",
      "[58]\tTest-rmse:0.42299\n",
      "[59]\tTest-rmse:0.42140\n",
      "[60]\tTest-rmse:0.41790\n",
      "[61]\tTest-rmse:0.41273\n",
      "[62]\tTest-rmse:0.41000\n",
      "[63]\tTest-rmse:0.40789\n",
      "[64]\tTest-rmse:0.40815\n",
      "[65]\tTest-rmse:0.40556\n",
      "[66]\tTest-rmse:0.40681\n",
      "[67]\tTest-rmse:0.40675\n",
      "[68]\tTest-rmse:0.40166\n",
      "[69]\tTest-rmse:0.40053\n",
      "[70]\tTest-rmse:0.39599\n",
      "[71]\tTest-rmse:0.39598\n",
      "[72]\tTest-rmse:0.39159\n",
      "[73]\tTest-rmse:0.38894\n",
      "[74]\tTest-rmse:0.38828\n",
      "[75]\tTest-rmse:0.38315\n",
      "[76]\tTest-rmse:0.37926\n",
      "[77]\tTest-rmse:0.37296\n",
      "[78]\tTest-rmse:0.37289\n",
      "[79]\tTest-rmse:0.37108\n",
      "[80]\tTest-rmse:0.37097\n",
      "[81]\tTest-rmse:0.36821\n",
      "[82]\tTest-rmse:0.36729\n",
      "[83]\tTest-rmse:0.36720\n",
      "[84]\tTest-rmse:0.36351\n",
      "[85]\tTest-rmse:0.36146\n",
      "[86]\tTest-rmse:0.36082\n",
      "[87]\tTest-rmse:0.35910\n",
      "[88]\tTest-rmse:0.35858\n",
      "[89]\tTest-rmse:0.35852\n",
      "[90]\tTest-rmse:0.35561\n",
      "[91]\tTest-rmse:0.35642\n",
      "[92]\tTest-rmse:0.35698\n",
      "[93]\tTest-rmse:0.35699\n",
      "[94]\tTest-rmse:0.35602\n",
      "[95]\tTest-rmse:0.35646\n",
      "[96]\tTest-rmse:0.35550\n",
      "[97]\tTest-rmse:0.35494\n",
      "[98]\tTest-rmse:0.35570\n",
      "[99]\tTest-rmse:0.35218\n",
      "[100]\tTest-rmse:0.35151\n",
      "[101]\tTest-rmse:0.34875\n",
      "[102]\tTest-rmse:0.34783\n",
      "[103]\tTest-rmse:0.34741\n",
      "[104]\tTest-rmse:0.34613\n",
      "[105]\tTest-rmse:0.34844\n",
      "[106]\tTest-rmse:0.34839\n",
      "[107]\tTest-rmse:0.34657\n",
      "[108]\tTest-rmse:0.34631\n",
      "[109]\tTest-rmse:0.34583\n",
      "[110]\tTest-rmse:0.34499\n",
      "[111]\tTest-rmse:0.34322\n",
      "[112]\tTest-rmse:0.34314\n",
      "[113]\tTest-rmse:0.34316\n",
      "[114]\tTest-rmse:0.34124\n",
      "[115]\tTest-rmse:0.34227\n",
      "[116]\tTest-rmse:0.34221\n",
      "[117]\tTest-rmse:0.34135\n",
      "[118]\tTest-rmse:0.34047\n",
      "[119]\tTest-rmse:0.34161\n",
      "[120]\tTest-rmse:0.34245\n",
      "[121]\tTest-rmse:0.34212\n",
      "[122]\tTest-rmse:0.34065\n",
      "[123]\tTest-rmse:0.34025\n",
      "[124]\tTest-rmse:0.34024\n",
      "[125]\tTest-rmse:0.33957\n",
      "[126]\tTest-rmse:0.33872\n",
      "[127]\tTest-rmse:0.34029\n",
      "[128]\tTest-rmse:0.34038\n",
      "[129]\tTest-rmse:0.33978\n",
      "[130]\tTest-rmse:0.33945\n",
      "[131]\tTest-rmse:0.33866\n",
      "[132]\tTest-rmse:0.33755\n",
      "[133]\tTest-rmse:0.33792\n",
      "[134]\tTest-rmse:0.33777\n",
      "[135]\tTest-rmse:0.33770\n",
      "[136]\tTest-rmse:0.33748\n",
      "[137]\tTest-rmse:0.33730\n",
      "[138]\tTest-rmse:0.33680\n",
      "[139]\tTest-rmse:0.33683\n",
      "[140]\tTest-rmse:0.33647\n",
      "[141]\tTest-rmse:0.33430\n",
      "[142]\tTest-rmse:0.33345\n",
      "[143]\tTest-rmse:0.33256\n",
      "[144]\tTest-rmse:0.33273\n",
      "[145]\tTest-rmse:0.33135\n",
      "[146]\tTest-rmse:0.33018\n",
      "[147]\tTest-rmse:0.32820\n",
      "[148]\tTest-rmse:0.32803\n",
      "[149]\tTest-rmse:0.32673\n",
      "[150]\tTest-rmse:0.32681\n",
      "[151]\tTest-rmse:0.32651\n",
      "[152]\tTest-rmse:0.32592\n",
      "[153]\tTest-rmse:0.32643\n",
      "[154]\tTest-rmse:0.32595\n",
      "[155]\tTest-rmse:0.32722\n",
      "[156]\tTest-rmse:0.32701\n",
      "[157]\tTest-rmse:0.32603\n",
      "[158]\tTest-rmse:0.32506\n",
      "[159]\tTest-rmse:0.32497\n",
      "[160]\tTest-rmse:0.32216\n",
      "[161]\tTest-rmse:0.32028\n",
      "[162]\tTest-rmse:0.32118\n",
      "[163]\tTest-rmse:0.32010\n",
      "[164]\tTest-rmse:0.31947\n",
      "[165]\tTest-rmse:0.31819\n",
      "[166]\tTest-rmse:0.31734\n",
      "[167]\tTest-rmse:0.31781\n",
      "[168]\tTest-rmse:0.31921\n",
      "[169]\tTest-rmse:0.31962\n",
      "[170]\tTest-rmse:0.31924\n",
      "[171]\tTest-rmse:0.31811\n",
      "[172]\tTest-rmse:0.31812\n",
      "[173]\tTest-rmse:0.31768\n",
      "[174]\tTest-rmse:0.31686\n",
      "[175]\tTest-rmse:0.31688\n",
      "[176]\tTest-rmse:0.31677\n",
      "[177]\tTest-rmse:0.31614\n",
      "[178]\tTest-rmse:0.31642\n",
      "[179]\tTest-rmse:0.31703\n",
      "[180]\tTest-rmse:0.31618\n",
      "[181]\tTest-rmse:0.31572\n",
      "[182]\tTest-rmse:0.31525\n",
      "[183]\tTest-rmse:0.31415\n",
      "[184]\tTest-rmse:0.31421\n",
      "[185]\tTest-rmse:0.31397\n",
      "[186]\tTest-rmse:0.31353\n",
      "[187]\tTest-rmse:0.31352\n",
      "[188]\tTest-rmse:0.31247\n",
      "[189]\tTest-rmse:0.31395\n",
      "[190]\tTest-rmse:0.31411\n",
      "[191]\tTest-rmse:0.31423\n",
      "[192]\tTest-rmse:0.31352\n",
      "[193]\tTest-rmse:0.31407\n",
      "[194]\tTest-rmse:0.31624\n",
      "[195]\tTest-rmse:0.31788\n",
      "[196]\tTest-rmse:0.31811\n",
      "[197]\tTest-rmse:0.31788\n",
      "[198]\tTest-rmse:0.31728\n",
      "Best RMSE: 0.31 in 189 rounds\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:5.48784\n",
      "[1]\tTest-rmse:4.93565\n",
      "[2]\tTest-rmse:4.43379\n",
      "[3]\tTest-rmse:3.98805\n",
      "[4]\tTest-rmse:3.59204\n",
      "[5]\tTest-rmse:3.22469\n",
      "[6]\tTest-rmse:2.91537\n",
      "[7]\tTest-rmse:2.63697\n",
      "[8]\tTest-rmse:2.38234\n",
      "[9]\tTest-rmse:2.15274\n",
      "[10]\tTest-rmse:1.95026\n",
      "[11]\tTest-rmse:1.76234\n",
      "[12]\tTest-rmse:1.58760\n",
      "[13]\tTest-rmse:1.45094\n",
      "[14]\tTest-rmse:1.32922\n",
      "[15]\tTest-rmse:1.20769\n",
      "[16]\tTest-rmse:1.11868\n",
      "[17]\tTest-rmse:1.02924\n",
      "[18]\tTest-rmse:0.95382\n",
      "[19]\tTest-rmse:0.88946\n",
      "[20]\tTest-rmse:0.83332\n",
      "[21]\tTest-rmse:0.78195\n",
      "[22]\tTest-rmse:0.74035\n",
      "[23]\tTest-rmse:0.70253\n",
      "[24]\tTest-rmse:0.66709\n",
      "[25]\tTest-rmse:0.63953\n",
      "[26]\tTest-rmse:0.61081\n",
      "[27]\tTest-rmse:0.59781\n",
      "[28]\tTest-rmse:0.58291\n",
      "[29]\tTest-rmse:0.56744\n",
      "[30]\tTest-rmse:0.55616\n",
      "[31]\tTest-rmse:0.54495\n",
      "[32]\tTest-rmse:0.53250\n",
      "[33]\tTest-rmse:0.52379\n",
      "[34]\tTest-rmse:0.51979\n",
      "[35]\tTest-rmse:0.50646\n",
      "[36]\tTest-rmse:0.49441\n",
      "[37]\tTest-rmse:0.48813\n",
      "[38]\tTest-rmse:0.48440\n",
      "[39]\tTest-rmse:0.47901\n",
      "[40]\tTest-rmse:0.47588\n",
      "[41]\tTest-rmse:0.46967\n",
      "[42]\tTest-rmse:0.46096\n",
      "[43]\tTest-rmse:0.46103\n",
      "[44]\tTest-rmse:0.46069\n",
      "[45]\tTest-rmse:0.45675\n",
      "[46]\tTest-rmse:0.45822\n",
      "[47]\tTest-rmse:0.45154\n",
      "[48]\tTest-rmse:0.45007\n",
      "[49]\tTest-rmse:0.45200\n",
      "[50]\tTest-rmse:0.44363\n",
      "[51]\tTest-rmse:0.43684\n",
      "[52]\tTest-rmse:0.43689\n",
      "[53]\tTest-rmse:0.43306\n",
      "[54]\tTest-rmse:0.43128\n",
      "[55]\tTest-rmse:0.42956\n",
      "[56]\tTest-rmse:0.42866\n",
      "[57]\tTest-rmse:0.42416\n",
      "[58]\tTest-rmse:0.42299\n",
      "[59]\tTest-rmse:0.42140\n",
      "[60]\tTest-rmse:0.41790\n",
      "[61]\tTest-rmse:0.41273\n",
      "[62]\tTest-rmse:0.41000\n",
      "[63]\tTest-rmse:0.40789\n",
      "[64]\tTest-rmse:0.40815\n",
      "[65]\tTest-rmse:0.40556\n",
      "[66]\tTest-rmse:0.40681\n",
      "[67]\tTest-rmse:0.40675\n",
      "[68]\tTest-rmse:0.40166\n",
      "[69]\tTest-rmse:0.40053\n",
      "[70]\tTest-rmse:0.39599\n",
      "[71]\tTest-rmse:0.39598\n",
      "[72]\tTest-rmse:0.39159\n",
      "[73]\tTest-rmse:0.38894\n",
      "[74]\tTest-rmse:0.38828\n",
      "[75]\tTest-rmse:0.38315\n",
      "[76]\tTest-rmse:0.37926\n",
      "[77]\tTest-rmse:0.37296\n",
      "[78]\tTest-rmse:0.37289\n",
      "[79]\tTest-rmse:0.37108\n",
      "[80]\tTest-rmse:0.37097\n",
      "[81]\tTest-rmse:0.36821\n",
      "[82]\tTest-rmse:0.36729\n",
      "[83]\tTest-rmse:0.36720\n",
      "[84]\tTest-rmse:0.36351\n",
      "[85]\tTest-rmse:0.36146\n",
      "[86]\tTest-rmse:0.36082\n",
      "[87]\tTest-rmse:0.35910\n",
      "[88]\tTest-rmse:0.35858\n",
      "[89]\tTest-rmse:0.35852\n",
      "[90]\tTest-rmse:0.35561\n",
      "[91]\tTest-rmse:0.35642\n",
      "[92]\tTest-rmse:0.35698\n",
      "[93]\tTest-rmse:0.35699\n",
      "[94]\tTest-rmse:0.35602\n",
      "[95]\tTest-rmse:0.35646\n",
      "[96]\tTest-rmse:0.35550\n",
      "[97]\tTest-rmse:0.35494\n",
      "[98]\tTest-rmse:0.35570\n",
      "[99]\tTest-rmse:0.35218\n",
      "[100]\tTest-rmse:0.35151\n",
      "[101]\tTest-rmse:0.34875\n",
      "[102]\tTest-rmse:0.34783\n",
      "[103]\tTest-rmse:0.34741\n",
      "[104]\tTest-rmse:0.34613\n",
      "[105]\tTest-rmse:0.34844\n",
      "[106]\tTest-rmse:0.34839\n",
      "[107]\tTest-rmse:0.34657\n",
      "[108]\tTest-rmse:0.34631\n",
      "[109]\tTest-rmse:0.34583\n",
      "[110]\tTest-rmse:0.34499\n",
      "[111]\tTest-rmse:0.34322\n",
      "[112]\tTest-rmse:0.34314\n",
      "[113]\tTest-rmse:0.34316\n",
      "[114]\tTest-rmse:0.34124\n",
      "[115]\tTest-rmse:0.34227\n",
      "[116]\tTest-rmse:0.34221\n",
      "[117]\tTest-rmse:0.34135\n",
      "[118]\tTest-rmse:0.34047\n",
      "[119]\tTest-rmse:0.34161\n",
      "[120]\tTest-rmse:0.34245\n",
      "[121]\tTest-rmse:0.34212\n",
      "[122]\tTest-rmse:0.34065\n",
      "[123]\tTest-rmse:0.34025\n",
      "[124]\tTest-rmse:0.34024\n",
      "[125]\tTest-rmse:0.33957\n",
      "[126]\tTest-rmse:0.33872\n",
      "[127]\tTest-rmse:0.34029\n",
      "[128]\tTest-rmse:0.34038\n",
      "[129]\tTest-rmse:0.33978\n",
      "[130]\tTest-rmse:0.33945\n",
      "[131]\tTest-rmse:0.33866\n",
      "[132]\tTest-rmse:0.33755\n",
      "[133]\tTest-rmse:0.33792\n",
      "[134]\tTest-rmse:0.33777\n",
      "[135]\tTest-rmse:0.33770\n",
      "[136]\tTest-rmse:0.33748\n",
      "[137]\tTest-rmse:0.33730\n",
      "[138]\tTest-rmse:0.33680\n",
      "[139]\tTest-rmse:0.33683\n",
      "[140]\tTest-rmse:0.33647\n",
      "[141]\tTest-rmse:0.33430\n",
      "[142]\tTest-rmse:0.33345\n",
      "[143]\tTest-rmse:0.33256\n",
      "[144]\tTest-rmse:0.33273\n",
      "[145]\tTest-rmse:0.33135\n",
      "[146]\tTest-rmse:0.33018\n",
      "[147]\tTest-rmse:0.32820\n",
      "[148]\tTest-rmse:0.32803\n",
      "[149]\tTest-rmse:0.32673\n",
      "[150]\tTest-rmse:0.32681\n",
      "[151]\tTest-rmse:0.32651\n",
      "[152]\tTest-rmse:0.32592\n",
      "[153]\tTest-rmse:0.32643\n",
      "[154]\tTest-rmse:0.32595\n",
      "[155]\tTest-rmse:0.32722\n",
      "[156]\tTest-rmse:0.32701\n",
      "[157]\tTest-rmse:0.32603\n",
      "[158]\tTest-rmse:0.32506\n",
      "[159]\tTest-rmse:0.32497\n",
      "[160]\tTest-rmse:0.32216\n",
      "[161]\tTest-rmse:0.32028\n",
      "[162]\tTest-rmse:0.32118\n",
      "[163]\tTest-rmse:0.32010\n",
      "[164]\tTest-rmse:0.31947\n",
      "[165]\tTest-rmse:0.31819\n",
      "[166]\tTest-rmse:0.31734\n",
      "[167]\tTest-rmse:0.31781\n",
      "[168]\tTest-rmse:0.31921\n",
      "[169]\tTest-rmse:0.31962\n",
      "[170]\tTest-rmse:0.31924\n",
      "[171]\tTest-rmse:0.31811\n",
      "[172]\tTest-rmse:0.31812\n",
      "[173]\tTest-rmse:0.31768\n",
      "[174]\tTest-rmse:0.31686\n",
      "[175]\tTest-rmse:0.31688\n",
      "[176]\tTest-rmse:0.31677\n",
      "[177]\tTest-rmse:0.31614\n",
      "[178]\tTest-rmse:0.31642\n",
      "[179]\tTest-rmse:0.31703\n",
      "[180]\tTest-rmse:0.31618\n",
      "[181]\tTest-rmse:0.31572\n",
      "[182]\tTest-rmse:0.31525\n",
      "[183]\tTest-rmse:0.31415\n",
      "[184]\tTest-rmse:0.31421\n",
      "[185]\tTest-rmse:0.31397\n",
      "[186]\tTest-rmse:0.31353\n",
      "[187]\tTest-rmse:0.31352\n",
      "[188]\tTest-rmse:0.31247\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.31247\n",
      "Train RMSE: 0.39757\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(dtest)\n",
    "print(\"Test RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_test ,y_pred))))\n",
    "    \n",
    "y_train_pred = best_model.predict(dtrain)\n",
    "print(\"Train RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_train_pred ,y_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'min_child_weight': 6,\n",
       " 'eta': 0.1,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'eval_metric': 'rmse'}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_inputs(train)\n",
    "\n",
    "max_depth = 3\n",
    "min_child_weight = 3\n",
    "subsample = 1\n",
    "colsample_bytree = 1\n",
    "objective = 'reg:squarederror'\n",
    "num_estimators = 442\n",
    "learning_rate = 0.1\n",
    "\n",
    "xgb = XGBRegressor(max_depth=max_depth,\n",
    "                min_child_weight=min_child_weight,\n",
    "                subsample=subsample,\n",
    "                colsample_bytree=colsample_bytree,\n",
    "                objective=objective,\n",
    "                n_estimators=num_estimators,\n",
    "                learning_rate=learning_rate, random_state= seed)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print('trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.30049\n",
      "Train RMSE: 0.24729\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "print(\"Test RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_test ,y_pred))))\n",
    "    \n",
    "y_train_pred = xgb.predict(X_train)\n",
    "print(\"Train RMSE: {:.5f}\".format(np.sqrt(metrics.mean_squared_error(y_train_pred ,y_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max_depth=3,min_child_weight=3,subsample=1,colsample_bytree=1,\n",
    "            objective='reg:squarederror',n_estimators=442, learning_rate=0.1, random_state= seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
